{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SARS-CoV-2 Research Challenge.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPivnpfZ/DXKVhIEbYzPLq3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jessetuglu/SARS-CoV-2-Research/blob/master/SARS_CoV_2_Research_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SaC0CpFaVez",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6JmcqoJaQtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import dependencies\n",
        "import json\n",
        "#To work with json file format\n",
        "import os\n",
        "#Directory/filepath use\n",
        "import pandas as pd\n",
        "#dataframes\n",
        "from tqdm import tqdm\n",
        "#adding a loading bar(see screenshot)\n",
        "import re\n",
        "#regular expressions library \n",
        "import matplotlib.pyplot as plt\n",
        "#graphing results\n",
        "import numpy as np\n",
        "#calculations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFyVXvnceIrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Unfortunately, the data was provided in a .json files so it was a little difficult to convert to manageable format. \n",
        "#I begin by creating an empty list to hold the data extracted from the files\n",
        "docs = []\n",
        "\n",
        "folder_path = \"/Users/jessetuglu/Desktop/2020-03-13\"\n",
        "#making the list of subfolders to iterate through\n",
        "directories = [\"biorxiv_medrxiv\",\"comm_use_subset\",\"noncomm_use_subset\"]\n",
        "#Swtiching the current working directory to the folder pathname \n",
        "os.chdir(\"/Users/jessetuglu/Desktop/2020-03-13\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe9pXNO9ldRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initial \"for\" loop to establish that same actions must be done to each folder. \n",
        "for a in directories:\n",
        "    #second \"for\" loop to access the files inside of the folders referenced in the list \"directories.\"As each main folder has a sub-folder of the same name, I had to {a} twice. \n",
        "    for b in tqdm(os.listdir(f\"{a}/{a}\")):\n",
        "        #defining individual file paths\n",
        "        file_path = f\"{a}/{a}/{b}\"\n",
        "        #opening files\n",
        "        jsons = json.load(open(file_path,\"rb\"))\n",
        "        #finding essentially what the \"headings\" are in the files. In this case, \"title\" is one of the metadata(headers) of the data.\n",
        "        title = jsons['metadata']['title']\n",
        "        #searching for certain formatting in the form of \"abstract\" classes. \n",
        "        try:\n",
        "            abst = jsons['abstract'][0]\n",
        "        except:\n",
        "            abst = \"\"\n",
        "        #setting empty string to add later\n",
        "        full_text = \"\"\n",
        "        #referencing each \"body_text\" heading. \n",
        "        for text in jsons['body_text']:\n",
        "            #adding the text to the previously defined string and then indenting for formatting.\n",
        "            full_text += text['text'] + \"\\n\\n\"   \n",
        "        #adding these strings to the list.\n",
        "        docs.append([title,abst,full_text])\n",
        "        #creating a pandas dataframe to house the data. \"Title\" being the title of the paper, \"abstract\" being the formatting and other information, and \"text\" being the \"body_text\" seen previously. \n",
        "df = pd.DataFrame(docs,columns=['title','abstract','text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRZy0wgOlfED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#After finally importing the json file data and converting it into plain text(strings) in a dataframe, it is now very easy to analyze. \n",
        "#create a dataframe containing the strings which have the keyword \"incubation.\"\n",
        "incubation = df[df['text'].str.contains('incubation')]\n",
        "#checking to make sure correct data has been placed into dataframe by displaying the first 5 samples\n",
        "print(incubation.head())\n",
        "#creating an array of such values.\n",
        "incubation_texts = incubation['text'].values\n",
        "#returns the number of strings with the keyword.\n",
        "print(len(incubation_texts))\n",
        "#creating a list to hold the incubation period data.\n",
        "incubation_periods = []\n",
        "#another \"for\" loop to iterate through the strings.\n",
        "for t in incubation_texts:\n",
        "    #by seperating the strings into individual sentences, it will be easier to analyze the incubation time.\n",
        "    for sentence in t.split(\". \"):\n",
        "        #checking to make sure only sentences with \"incubation\" in them are viewed. \n",
        "        if \"incubation\" in sentence:\n",
        "            #identifying whether \"day\" is also in sentence\n",
        "            single_day = re.findall(r\" \\d{1,2} day\",sentence)\n",
        "            #if there is one found..\n",
        "            if len(single_day) == 1:\n",
        "                #finding the number attached to the substring \"day.\"\n",
        "                num = single_day[0].split(\" \")\n",
        "                #placing that number in the list I referenced before. \n",
        "                incubation_periods.append(float(num[1]))\n",
        "#how many data points\n",
        "print(\"Total number of recorded times: \" + str(len(incubation_periods)))\n",
        "#this is a python array now so use numpy to calculate average incubation time\n",
        "print(\"Average incubation time is: \"+ np.mean(incubation_periods))\n",
        "#graph\n",
        "plt.hist(incubation_periods,bins= 40)\n",
        "plt.xlabel(\"Incubation Period (days)\")\n",
        "plt.ylabel(\"Number of cases\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqq5fBCLzfi4",
        "colab_type": "text"
      },
      "source": [
        "![](https://drive.google.com/uc?id=1sJBjfmL78grTF88OvqZPuI7i_v5tn1eb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPexy-USlnXD",
        "colab_type": "text"
      },
      "source": [
        "The folowing two boxes display a very broad search method through the nearly 11700 json files. Searching for keywords such as \"transmission\" or \"vaccine\" one is easily able to find related sentences and, hopefully, some useful information. When run, the program converts the list into a CSV which can then be downloaded for further use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaXpYUjylhnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TRANSMISSION\n",
        "transmission = df[df['text'].str.contains('transmission')]\n",
        "transmission_texts = transmission['text'].values\n",
        "transmission_sentences = []\n",
        "for t in transmission_texts:\n",
        "    for sentence in t.split(\". \"):\n",
        "        if (\"transmission\" and \"SARS-CoV-2\")in sentence:\n",
        "            transmission_sentences.append(sentence)\n",
        "#print(len(transmission_sentences))\n",
        "transmission_sentences_df = pd.DataFrame(transmission_sentences,columns=[\"Sentences\"])\n",
        "#print(transmission_sentences_df.head())\n",
        "transmission_sentences_df.to_csv('transmission_sentences.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M534BK0llAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#VACCINES\n",
        "vaccine = df[df['text'].str.contains('vaccine')]\n",
        "vaccine_texts = vaccine['text'].values\n",
        "vaccine_sentences = []\n",
        "for t in vaccine_texts:\n",
        "    for sentence in t.split(\". \"):\n",
        "        if (\" vaccine \" and \"SARS-CoV-2\")in sentence:\n",
        "            vaccine_sentences.append(sentence)\n",
        "#print(len(vaccine_sentences))\n",
        "vaccine_sentences_df = pd.DataFrame(vaccine_sentences,columns=[\"Sentences\"])\n",
        "#print(vaccine_sentences_df.head())\n",
        "vaccine_sentences_df.to_csv('vaccine_sentences.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
